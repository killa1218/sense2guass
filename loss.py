# coding=utf8from __future__ import print_functionfrom __future__ import divisionfrom options import Options as optimport tensorflow as tffrom tensorflow.nn import relu as act# from tensorflow.nn import sigmoid as act# from tensorflow.nn import tanh as actfrom m_step.utils.distance import distimport randomdef skipGramLoss(stc, sLabel):    '''Return the Tensorflow graph of skip-gram score of the sentence, the sentence is an array of Word()'''    totalSum = tf.constant(0., dtype=tf.float32)    for i in range(len(stc)):        tmpSum = tf.constant(0., dtype=tf.float32)        for offset in range(1, opt.windowSize + 1):            if i - offset > -1:                tmpSum += act(dist((stc[i], sLabel[i]), (stc[i - offset], sLabel[i - offset])), name="loss-ActivationFunction")            if i + offset < len(stc):                tmpSum += act(dist((stc[i], sLabel[i]), (stc[i + offset], sLabel[i + offset])), name="loss-ActivationFunction")        totalSum += tmpSum / (((i + opt.windowSize) if i + opt.windowSize < len(stc) else (len(stc) - 1)) - ((i - opt.windowSize) if i - opt.windowSize > -1 else 0))   # Full window        # totalSum += tmpSum / ((i if i == 0 else i) if i < opt.windowSize else opt.windowSize)   # Half window    return totalSumdef avgSkipGramLoss(stc, sLabel):    return skipGramLoss(stc, sLabel) / len(stc)def skipGramNCELoss(stc, sLabel, vocab):    '''Return the Tensorflow graph of skip-gram score with negative sampling of the sentence, the sentence is an array of Word()'''    totalSum = tf.constant(0., dtype=tf.float32)    for i in range(len(stc)):        for offset in range(1, opt.windowSize + 1):            if i - offset > -1:                sampleWord = stc[i]                while sampleWord is not stc[i]:                    sampleWord = vocab.getWord(random.randint(0, vocab.size - 1))                totalSum += act(opt.margin - dist((stc[i], sLabel[i]), (stc[i - offset], sLabel[i - offset])) + dist((stc[i], sLabel[i]), (sampleWord, 0)), name="loss-NCEMarginLoss")            if i + offset < len(stc):                sampleWord = stc[i]                while sampleWord is not stc[i]:                    sampleWord = vocab.getWord(random.randint(0, vocab.size - 1))                totalSum += act(opt.margin - dist((stc[i], sLabel[i]), (stc[i + offset], sLabel[i + offset])) + dist((stc[i], sLabel[i]), (sampleWord, 0)), name="loss-NCEMarginLoss")        # totalSum += tmpSum / (((i + opt.windowSize) if i + opt.windowSize < len(stc) else (len(stc) - 1)) - ((i - opt.windowSize) if i - opt.windowSize > -1 else 0))   # Full window        # totalSum += tmpSum / ((i if i == 0 else i) if i < opt.windowSize else opt.windowSize)   # Half window    return totalSum